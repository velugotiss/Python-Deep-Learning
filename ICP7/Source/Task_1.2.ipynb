{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_1.2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xj6LdqH5m9h",
        "outputId": "c0727644-ced7-4568-b31f-eadd41bf451f"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "\r\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVJzLdWp51gr"
      },
      "source": [
        "#change the tfidfvectorizer to use bigram\r\n",
        "tfidf_Vect = TfidfVectorizer()\r\n",
        "tfidf_Vect1 = TfidfVectorizer(ngram_range=(1, 2))\r\n",
        "tfidf_Vect2 = TfidfVectorizer(stop_words='english')\r\n",
        "\r\n",
        "X_train_tfidf = tfidf_Vect.fit_transform(twenty_train.data)\r\n",
        "X_train_tfidf1 = tfidf_Vect1.fit_transform(twenty_train.data)\r\n",
        "X_train_tfidf2 = tfidf_Vect2.fit_transform(twenty_train.data)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XolmCOG6GnM",
        "outputId": "628764d8-debb-4f54-fd28-7ee836ad1c80"
      },
      "source": [
        "clf = MultinomialNB()\r\n",
        "clf.fit(X_train_tfidf, twenty_train.target)\r\n",
        "\r\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\r\n",
        "X_test_tfidf = tfidf_Vect.transform(twenty_test.data)\r\n",
        "\r\n",
        "predicted = clf.predict(X_test_tfidf)\r\n",
        "\r\n",
        "score = metrics.accuracy_score(twenty_test.target, predicted)\r\n",
        "print(\"TfidfVectorizer score: \" + str(score))\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfidfVectorizer score: 0.7738980350504514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDdNNcyH6OGb",
        "outputId": "10b798df-4402-4fbf-fec7-8b77415d6a1d"
      },
      "source": [
        "#score for X_train_tfidf1\r\n",
        "clf1 = MultinomialNB()\r\n",
        "clf1.fit(X_train_tfidf1, twenty_train.target)\r\n",
        "\r\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\r\n",
        "X_test_tfidf1 = tfidf_Vect1.transform(twenty_test.data)\r\n",
        "\r\n",
        "predicted1 = clf1.predict(X_test_tfidf1)\r\n",
        "score1 = metrics.accuracy_score(twenty_test.target, predicted1)\r\n",
        "print(\"TfidfVectorizer score with ngram: \" + str(score1))\r\n",
        "\r\n",
        "#score for X_train_tfidf2\r\n",
        "clf2 = MultinomialNB()\r\n",
        "clf2.fit(X_train_tfidf2, twenty_train.target)\r\n",
        "\r\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\r\n",
        "X_test_tfidf2 = tfidf_Vect2.transform(twenty_test.data)\r\n",
        "\r\n",
        "predicted2 = clf2.predict(X_test_tfidf2)\r\n",
        "\r\n",
        "score3 = metrics.accuracy_score(twenty_test.target, predicted2)\r\n",
        "print(\"TfidfVectorizer score with english stop words: \" + str(score3))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfidfVectorizer score with ngram: 0.765400955921402\n",
            "TfidfVectorizer score with english stop words: 0.8169144981412639\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}